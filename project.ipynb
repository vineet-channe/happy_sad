{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955528e-bfee-4eeb-9858-48abfc25623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eebd18-6e81-4f42-8252-ac998aced250",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dda06f-1d97-42ee-9507-7dc97bdfd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81e205-5233-4ed2-95ec-065e040cd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_demo = cv2.imread(os.path.join('data','happy','1-2.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faab5b5-07be-4b09-a6a0-f8809b728714",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_demo.shape  #pixels height, pixels width, 3 channels means its coloured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ea669-d518-4276-b406-05a275e3e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image_demo,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb10656-ac71-4b5a-b8ab-73c9d5ca4e18",
   "metadata": {},
   "source": [
    "REMOVE DODGY IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516e3a7-e35b-40bf-85e1-2117c1b30a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84591ab7-9b7f-48d6-9820-fd0e61f88cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78373c0-f792-4e43-a796-6079c4e08900",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpg', 'jpeg', 'png','bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f0ba3-9a5c-4112-ac6b-57c744fcf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    image_class_path = os.path.join(data_dir, image_class)\n",
    "    if os.path.isdir(image_class_path):\n",
    "        for image in os.listdir(os.path.join(image_class_path)):\n",
    "            image_path = os.path.join(image_class_path, image)\n",
    "            try:\n",
    "                img = cv2.imread(image_path) # reads the image in opencv\n",
    "                tip = imghdr.what(image_path) # checks the extensions\n",
    "                if tip not in image_exts:\n",
    "                    print(\"Issue with image extension\".format(image_path))\n",
    "                    os.remove(image_path)\n",
    "            except Exception as e:\n",
    "                print('Issue with image {}'.format(image_path))\n",
    "                # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7249cb-e6e0-4a9f-b08d-f89de7fc1871",
   "metadata": {},
   "source": [
    "LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5360d3e-cf6f-4b82-8892-ad1fcb522471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7148f8-b07c-4ed4-b594-c75d6162ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741e658-0973-4569-8c7b-9eacaec24455",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c958931-f39a-4860-bd20-64a49a6e87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a483470-6ad0-4a03-b576-52fa381c0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b13da-ffaf-4cc1-bea2-db1b641b7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c7034-f509-40ed-82fd-03d59a681e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc144c66-f8fd-476d-b347-1c6d73f35103",
   "metadata": {},
   "source": [
    "SCALE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd6311-63c5-469d-a875-5a0454f20818",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b2f7d-c234-4eda-b5ad-3eb8a2ea790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db57797-3423-49d8-a517-9f27877995e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553d831-c0bd-4709-9384-038a28187e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34515f89-c69e-444b-bddd-b81ee4c6ea82",
   "metadata": {},
   "source": [
    "SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a29f9-058f-45c4-8e6b-0f115838e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) ##number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c7c75-a511-42da-9b42-cf88ccd91b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7) ##used to train model\n",
    "val_size = int(len(data)*.2) ##used to evalute model while training to fine tune the model\n",
    "test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b3c0b-d5e6-45fe-b33d-8ac7e0e48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size + val_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703b5ad-14a8-4c6e-be96-370727321e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1038919-70f1-45b6-a5c6-de083d1db2fe",
   "metadata": {},
   "source": [
    "BUILD A NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51534e8-5344-4cba-af67-252cadc1a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00c8c8-1930-4df1-a188-22ebf4509e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bf489-ad22-4ba4-bbb4-33d68ba272c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu', input_shape = (256, 256, 3))) # inputshape is only in the first layer and '1' is the stride\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D()) \n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D()) \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation ='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973bbb72-605f-4791-b32e-11810392e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f5b24-139c-4272-9794-d1669ec825ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7de5a8-a1e4-4863-a5f8-270714866a22",
   "metadata": {},
   "source": [
    "TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a2b5a-d4bf-452d-9b00-12342aa54c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d3334-e0f4-4cb0-91ba-4fef81201059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir) ##used to log data for later verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb8d20-dc87-412d-baed-c074dc4b0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data = val, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3abf62-a274-4f07-8f97-ae77ac0629d5",
   "metadata": {},
   "source": [
    "PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c823a9b-21de-42d5-bb92-9b65cdd08270",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'teal', label = 'Loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'orange', label = 'Validation Loss')\n",
    "plt.title('LOSS')\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b03d5-1b33-4551-aee6-7e47c5a2ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'teal', label = 'Accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color = 'orange', label = 'Validation Accuracy')\n",
    "plt.title('ACCURACY')\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899c82-9b50-4ac9-b8ae-affbae6f8992",
   "metadata": {},
   "source": [
    "EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba28ec-95d1-4f8b-bf9d-11d57b18e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36522e-948c-43a6-9686-e31682925ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = Precision()\n",
    "re = Recall()\n",
    "ba = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07298848-e3d4-4635-afc0-19912da2e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pe.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    ba.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4572d3-9a42-4898-ad31-b473715842ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_result = pe.result().numpy()\n",
    "re_result = re.result().numpy()\n",
    "ba_result = ba.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8f8c0-8217-4d15-8792-c3b124adb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pe_result)\n",
    "print(re_result)\n",
    "print(ba_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c7988-d22c-4f7b-8d43-70f33d74e5e8",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a92a55-b4a7-4646-a535-9e700795463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c445ac-9bbe-44ca-9404-c565a160fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('happy.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775af60e-b56c-4758-b8b1-4e167a718fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize_img.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472390f-b920-443c-a774-2fd1c6f8056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize_img/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef9e25-0d9b-4df3-a472-583207f05d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243519d9-14e6-4f00-a425-47c0807d4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Sad')\n",
    "else:\n",
    "    print(f'Predicted class is Happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf1bd6-8891-4bf8-b9dd-131567265ca0",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b4deb-669b-4c98-928c-261f557a0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8e0b0-fc9d-438e-8264-d1d47b023836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','imageclassifier2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bd1a0-d15a-4997-b1e6-266f2faf0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('imageclassifier2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961a718-e9f6-4d1e-bbc1-b09c8cfa1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5f1b3-9f95-43e6-b15c-0502b33e820e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Imageclassifciation",
   "language": "python",
   "name": "imageclassifciation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
